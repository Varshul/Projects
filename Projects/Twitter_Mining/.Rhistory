access_token_secret = "wZsZoxIjbBATDfUUcAw4htgICrbExb52h3JwgtvDA7509"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
searchTwitter("iphone")
ARG.list <- searchTwitter('#ARG #FIFA', n=1000, cainfo="cacert.pem")
?searchTwitter
ARG.list <- searchTwitter('#ARG #FIFA', n=1000, cainfo="cacert.pem")
ARG.df = twListToDF(ARG.list)
ARG.list <- searchTwitter('#ARG #FIFA', n=1000)
ARG.df = twListToDF(ARG.list)
ARG.df
ARG.list <- searchTwitter('#ARG #FIFA', n=1000)
ARG.df = twListToDF(ARG.list)
ARG.list
download.file(url="http://curl.haxx.se/ca/cacert.pem",
destfile="cacert.pem")
download.file(url="http://curl.haxx.se/ca/cacert.pem",
destfile="cacert.pem")
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "E89vXwkpB4MvW0FFr3O6wMGxr"
consumerSecret <- "kvPM5KJadM7jMAi7EFjJXep9UaQoHcyq8tPag1ktruAcWEzhuX"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
library(twitteR)
> library(ROAuth)
> library(RCurl)
library(twitteR)
library(ROAuth)
library(RCurl)
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
twitCred$handshake(cainfo="cacert.pem")
registerTwitterOAuth(twitCred)
registerTwitterOAuth(twitCred)
library(devtools)
library(twitteR)
api_key = "E89vXwkpB4MvW0FFr3O6wMGxr"
api_secret = "kvPM5KJadM7jMAi7EFjJXep9UaQoHcyq8tPag1ktruAcWEzhuX"
access_token = "24521872-ohMx6NMgeBJgVR2V1qLo9ckqwu9HqAQG26wfebUJN"
access_token_secret = "wZsZoxIjbBATDfUUcAw4htgICrbExb52h3JwgtvDA7509"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
save(list="twitCred", file="twitteR_credentials")
library (twitteR)
load("twitteR_credentials")
registerTwitterOAuth(twitCred)
?setup_twitter_oauth
setup_twitter_oauth("E89vXwkpB4MvW0FFr3O6wMGxr", "kvPM5KJadM7jMAi7EFjJXep9UaQoHcyq8tPag1ktruAcWEzhuX")
s <- searchTwitter('#United', cainfo="cacert.pem")
library(devtools)
library(twitteR)
api_key = "E89vXwkpB4MvW0FFr3O6wMGxr"
api_secret = "kvPM5KJadM7jMAi7EFjJXep9UaQoHcyq8tPag1ktruAcWEzhuX"
access_token = "24521872-ohMx6NMgeBJgVR2V1qLo9ckqwu9HqAQG26wfebUJN"
access_token_secret = "wZsZoxIjbBATDfUUcAw4htgICrbExb52h3JwgtvDA7509"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
rm(list=ls())
library(twitteR)
library(ROAuth)
library(RCurl)
download.file(url="http://curl.haxx.se/ca/cacert.pem",
destfile="cacert.pem")
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "E89vXwkpB4MvW0FFr3O6wMGxr"
consumerSecret <- "kvPM5KJadM7jMAi7EFjJXep9UaQoHcyq8tPag1ktruAcWEzhuX"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
twitCred$handshake(cainfo="cacert.pem")
registerTwitterOAuth(twitCred)
registerTwitterOAuth(twitCred)
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret, credentials_file=NULL)
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
?setup_twitter_oauth
setup_twitter_oauth(consumer_key, consumer_secret)
setup_twitter_oauth(consumerKey, consumerSecret)
setup_twitter_oauth(consumerKey, consumerSecret)
registerTwitterOAuth(twitCred)
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
setup_twitter_oauth(consumerKey, consumerSecret)
twitCred$handshake(cainfo="cacert.pem")
registerTwitterOAuth(twitCred)
library(httr)
# 1. Find OAuth settings for twitter:
#    https://dev.twitter.com/docs/auth/oauth
oauth_endpoints("twitter")
# 2. Register an application at https://apps.twitter.com/
#    Insert your values below - if secret is omitted, it will look it up in
#    the TWITTER_CONSUMER_SECRET environmental variable.
myapp <- oauth_app("twitter", key = "E89vXwkpB4MvW0FFr3O6wMGxr")
# 3. Get OAuth credentials
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
# 4. Use API
req <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",
config(token = twitter_token))
stop_for_status(req)
content(req)
myapp <- oauth_app("twitter", key = "TYrWFPkFAkn4G5BbkWINYw", secret = "kvPM5KJadM7jMAi7EFjJXep9UaQoHcyq8tPag1ktruAcWEzhuX")
# 3. Get OAuth credentials
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
# 4. Use API
req <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",
config(token = twitter_token))
stop_for_status(req)
content(req)
myapp = oauth_app("twitter",
key="E89vXwkpB4MvW0FFr3O6wMGxr",secret="kvPM5KJadM7jMAi7EFjJXep9UaQoHcyq8tPag1ktruAcWEzhuX")
sig = sign_oauth1.0(myapp,
token = "24521872-n42f5gUlsZjewEos5IR7wJRqlBpXWPJPRsSYahYaZ",
token_secret = "jlLLOnx66T8D8He3i7QgGeSZIVJQ9zJG5U4xDN2IJ8Nv5")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
BRA.list <- searchTwitter('#BRA #FIFA', n=1000, cainfo="cacert.pem")
?httr
json2 = jsonlite::fromJSON(toJSON(json1))
install.packages("ROAuth")
install.packages("twitteR")
install.packages("wordcloud")
install.packages("ROAuth")
install.packages("ROAuth")
install.packages("ROAuth")
install.packages("ROAuth")
install.packages("ROAuth")
install.packages("twitteR")
install.packages("wordcloud")
install.packages("tm")
library("ROAuth")
library("twitteR")
library("wordcloud")
library("tm")
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
cred <- OAuthFactory$new(consumerKey='E89vXwkpB4MvW0FFr3O6wMGxr',
consumerSecret='kvPM5KJadM7jMAi7EFjJXep9UaQoHcyq8tPag1ktruAcWEzhuX',
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
cred$handshake(cainfo="cacert.pem")
cred$handshake(cainfo="cacert.pem")
cred$handshake(cainfo="cacert.pem")
cred$handshake(cainfo="cacert.pem")
2200599
cred$handshake(cainfo="cacert.perm")
cred$handshake(cainfo="cacert.pem")
save(cred, file="twitter_authentication.Rdata")
registerTwitterOAuth(cred)
r_stats<- searchTwitter("#Rstats", n=1500, cainfo="cacert.pem")
BRA.list <- searchTwitter('#BRA #FIFA', n=1000, cainfo="cacert.pem")
BRA.df = twListToDF(BRA.list)
BRA.df = twListToDF(BRA.list)
length(r_stats)
r_stats<- searchTwitter("#Rstats", n=1500, cainfo="cacert.pem")
r_stats<- searchTwitter('#Rstats', n=1500, cainfo="cacert.pem")
r_stats<- searchTwitter('#PakSchoolSiege', n=1500, cainfo="cacert.pem")
r_stats<- searchTwitter('#PakSchoolSiege', n=15, cainfo="cacert.pem")
length(r_stats)
ARG.list <- searchTwitter('#ARG #FIFA', n=1000, cainfo="cacert.pem")
ARG.df = twListToDF(ARG.list)
BRA.list <- searchTwitter('#BRA #FIFA', n=1000, cainfo="cacert.pem")
BRA.df = twListToDF(BRA.list)
head(BRA.list)
GER.list <- searchTwitter('#GER #FIFA', n=1000, cainfo="cacert.pem")
GER.df = twListToDF(GER.list)
NED.list <- searchTwitter('#NED #FIFA', n=1000, cainfo="cacert.pem")
NED.df = twListToDF(NED.list)
library (plyr)
library (stringr)
score.sentiment = function(sentences, pos.words, neg.words,.progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array ("a") of scores back, so we use
# "l" + "a" + "ply" = "laply":
good.smiley <- c(":)")
bad.smiley <- c(":(",";)",":'",":P")
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub(":)", 'awsum', sentence)
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
#Load sentiment word lists
hu.liu.pos = scan('C:/temp/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('C:/temp/negative-words.txt', what='character', comment.char=';')
#Add words to list
pos.words = c(hu.liu.pos, 'upgrade', 'awsum')
neg.words = c(hu.liu.neg, 'wtf', 'wait','waiting', 'epicfail', 'mechanical',"suspension","no")
team = c("vs.","vs","versus")
#convert text to factor
ARG.df$text<-as.factor(ARG.df$text)
BRA.df$text<-as.factor(BRA.df$text)
NED.df$text<-as.factor(NED.df$text)
GER.df$text<-as.factor(GER.df$text)
#calculate all the scores
ARG.scores = score.sentiment(ARG.df$text, pos.words,neg.words, .progress='text')
BRA.scores = score.sentiment(BRA.df$text, pos.words,neg.words, .progress='text')
NED.scores = score.sentiment(NED.df$text,pos.words,neg.words, .progress='text')
GER.scores = score.sentiment(GER.df$text,pos.words,neg.words, .progress='text')
ARG.scores$Team = 'Argentina'
BRA.scores$Team = 'Brazil'
NED.scores$Team = 'Netherland'
GER.scores$Team = 'Germany'
#Check the negative tweets. What made them negative
ARG.scores.2 = subset(ARG.scores,ARG.scores$score < 0)
head(ARG.scores.2)
# Final outputs
hist(ARG.scores$score)
hist(BRA.scores$score)
hist(NED.scores$score)
hist(GER.scores$score)
table(ARG.scores$score)
table(BRA.scores$score)
table(NED.scores$score)
table(GER.scores$score)
head(all.scores)
all.scores = rbind(ARG.scores, NED.scores, GER.scores,BRA.scores)
table(all.scores$score,all.scores$Team)
ggplot(data=all.scores) + # ggplot works on data.frames, always
geom_bar(mapping=aes(x=score, fill=Team), binwidth=1) +
facet_grid(Team~.) + # make a separate plot for each hashtag
theme_bw() + scale_fill_brewer() # plain display, nicer colors
library(ggplot2)
score.sentiment = function(sentences, pos.words, neg.words,.progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array ("a") of scores back, so we use
# "l" + "a" + "ply" = "laply":
good.smiley <- c(":)")
bad.smiley <- c(":(",";)",":'",":P")
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub(":)", 'awsum', sentence)
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
#Load sentiment word lists
hu.liu.pos = scan('C:/temp/positive-words.txt', what='character', comment.char=';')
hu.liu.neg = scan('C:/temp/negative-words.txt', what='character', comment.char=';')
#Add words to list
pos.words = c(hu.liu.pos, 'upgrade', 'awsum')
neg.words = c(hu.liu.neg, 'wtf', 'wait','waiting', 'epicfail', 'mechanical',"suspension","no")
team = c("vs.","vs","versus")
#convert text to factor
ARG.df$text<-as.factor(ARG.df$text)
BRA.df$text<-as.factor(BRA.df$text)
NED.df$text<-as.factor(NED.df$text)
GER.df$text<-as.factor(GER.df$text)
#calculate all the scores
ARG.scores = score.sentiment(ARG.df$text, pos.words,neg.words, .progress='text')
BRA.scores = score.sentiment(BRA.df$text, pos.words,neg.words, .progress='text')
NED.scores = score.sentiment(NED.df$text,pos.words,neg.words, .progress='text')
GER.scores = score.sentiment(GER.df$text,pos.words,neg.words, .progress='text')
ARG.scores$Team = 'Argentina'
BRA.scores$Team = 'Brazil'
NED.scores$Team = 'Netherland'
GER.scores$Team = 'Germany'
#Check the negative tweets. What made them negative
ARG.scores.2 = subset(ARG.scores,ARG.scores$score < 0)
head(ARG.scores.2)
# Final outputs
hist(ARG.scores$score)
hist(BRA.scores$score)
hist(NED.scores$score)
hist(GER.scores$score)
table(ARG.scores$score)
table(BRA.scores$score)
table(NED.scores$score)
table(GER.scores$score)
head(all.scores)
all.scores = rbind(ARG.scores, NED.scores, GER.scores,BRA.scores)
table(all.scores$score,all.scores$Team)
ggplot(data=all.scores) + # ggplot works on data.frames, always
geom_bar(mapping=aes(x=score, fill=Team), binwidth=1) +
facet_grid(Team~.) + # make a separate plot for each hashtag
theme_bw() + scale_fill_brewer() # plain display, nicer colors
registerTwitterOAuth(cred)
r_stats<- searchTwitter("#PakSchoolSiege", n=1500, cainfo="cacert.pem")
r_stats<- searchTwitter("#PakSchoolSiege", n=500, cainfo="cacert.pem")
length(r_stats)
r_stats_text <- sapply(r_stats, function(x) x$getText())
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()))
wordcloud(r_stats_text_corpus)
getwd()
r_stats<- searchTwitter("#PakSchoolSiege", n=500, cainfo="cacert.pem")
r_stats_text <- sapply(r_stats, function(x) x$getText())
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus,
content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')),
mc.cores=1
)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower), mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation, mc.cores=1)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()), mc.cores=1)
wordcloud(r_stats_text_corpus)
setwd("F:/varshul/R/Projects/Twitter")
library(RColorBrewer)
pal2 <- brewer.pal(8,"Dark2")
wordcloud(r_stats_text_corpus,min.freq=2,max.words=100, random.order=T, colors=pal2)
ARG.list <- searchTwitter('#ARG #FIFA', n=1000, cainfo="cacert.pem")
ARG.df = twListToDF(ARG.list)
BRA.list <- searchTwitter('#BRA #FIFA', n=1000, cainfo="cacert.pem")
BRA.df = twListToDF(BRA.list)
head(BRA.list)
GER.list <- searchTwitter('#GER #FIFA', n=1000, cainfo="cacert.pem")
GER.df = twListToDF(GER.list)
NED.list <- searchTwitter('#NED #FIFA', n=1000, cainfo="cacert.pem")
NED.df = twListToDF(NED.list)
test <- read.csv("F:/varshul/R/Projects/Bike Sharing/test.csv")
View(test)
train <- read.csv("F:/varshul/R/Projects/Bike Sharing/train.csv")
View(train)
head(train)
names(train)
names(test)
sampleSubmission <- read.csv("C:/Users/Laktok/Downloads/sampleSubmission.csv")
View(sampleSubmission)
names(SampleSubmission)
names(sampleSubmission)
dim(sampleSubmission)
dim(test)
dim(train)
str(train)
head(train$datetime)
head(train$datetime,50)
head(train$datetime,25)
nrow(train)/24
nrow(train)
10886/24
nrow(test)
nrow(test)/24
10886/24
tail(train$datetime,)
train$datetime
str(train$datetime)
tail(train$datetime,24)
tail(train$datetime,48)
summary(train$datetime)
table(train$datetime)
table(train$season)
table(train$holiday)
table(train$workingday)
table(train$weather)
train$count[which(train$weather==4),]
train$count[which(train$weather==4)]
table(train$temp)
train$count[which(train$temp==41)]
train$count[which(train$temp==.82)]
table(train$atemp)
train$count[which(train$temp==45.555)]
train$count[which(train$temp==45.455)]
train$count[which(train$atemp==45.455)]
train$count[which(train$atemp==.76)]
train$count[which(train$atemp==44.695)]
table(train$humididyt)
table(train$humidity)
train$count[which(train$humidity==100)]
summary(train$count[which(train$humidity==100)])
summary(train$count[which(train$humidity==0)])
train$count[which(train$humidity==0)]
table(train$casual)
table(train$registered)
summary(table(train$count))
summary((train$count))
table((train$count==1))
which((train$casual+train$registered!)=train$count)
which((train$casual+train$registered)!=train$count)
which((train$casual+train$registered)==train$count)
summary(which((train$casual+train$registered)==train$count))
table(which((train$casual+train$registered)==train$count))
table(which((train$casual+train$registered)!=train$count))
prop.table(table(train$season,train$casual),2)
summary(train$casual)
hist(train$casual)
qplot(casual, data=train)
qplot(casual, data=train,color=season)
qplot(casual, data=train,color=holiday)
?qplot
qplot(casual, data=train,facets=.~season)
table(train$season)
qplot(registered, data=train,facets=.~season)
qplot(casual, data=train,facets=.~season)
qplot(casual, data=train)
qplot(casual, data=train,color="red")
qplot(casual, data=train,color="red",binwidth=2)
summary(which(train$casual)==0)
summary(which(train$casual==0)
)
table(which(train$casual==0))
(which(train$casual==0))
str(which(train$casual==0))
98600/nrow(train)
str(which(train$casual==1))
str(which(train$casual==2))
str(which(train$casual==3))
str(which(train$casual==4))
str(which(train$casual==5))
str(which(train$casual==6))
str(which(train$casual==7))
str(which(train$casual==8))
str(which(train$casual==9))
str(which(train$casual==10))
str(which(train$casual==11))
str(which(train$casual==12))
str(which(train$casual==25))
str(which(train$casual==100))
str(which(train$casual==301))
str(which(train$casual==300))
str(which(train$casual==303))
str(which(train$casual==304))
fit <- rpart(casual ~ season, data = train)
fit <- rpart(casual ~ season, data = train, method="anova")
?rpart
library(rpart)
fit <- rpart(casual ~ season, data = train, method="anova")
fancyRpartPlot(fit)
library(rpart.plot)
fancyRpartPlot(fit)
library(rattle)
fancyRpartPlot(fit)
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(season = test$season, casual = Prediction)
write.csv(submit, file = "Submission.csv", row.names = FALSE)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(season = test$season, casual = Prediction)
write.csv(submit, file = "Submission.csv", row.names = FALSE)
fit <- rpart(casual ~ season, data = train, method="anova")
fit <- rpart(casual ~ season, data = train, method="class")
fancyRpartPlot(fit)
fit <- rpart(casual ~ season, data = train, method="anova")
fancyRpartPlot(fit)
Prediction <- predict(fit, test, type = "class")
?predict
fit <- rpart(casual ~ season, data = train, method="class")
Prediction <- predict(fit, test, type = "class")
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(season = test$season, casual = Prediction)
write.csv(submit, file = "Submission.csv", row.names = FALSE)
Submission <- read.csv("F:/varshul/R/Projects/Twitter/Submission.csv")
View(Submission)
fit <- rpart(casual ~ season, data = train, method="anova")
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(season = test$season, casual = Prediction)
write.csv(submit, file = "Submission.csv", row.names = FALSE)
Submission <- read.csv("F:/varshul/R/Projects/Twitter/Submission.csv")
View(Submission)
